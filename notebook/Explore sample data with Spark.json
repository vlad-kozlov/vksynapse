{
	"name": "Explore sample data with Spark",
	"properties": {
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "SampleSpark",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "4b5aaa51-e851-490d-90c4-7d7cdad3c97e"
			}
		},
		"metadata": {
			"saveOutput": true,
			"synapse_widget": {
				"version": "0.1",
				"state": {
					"958e0e0d-ae1c-4594-902f-6719ad8938a4": {
						"type": "Synapse.DataFrame",
						"sync_state": {
							"table": {
								"rows": [
									{
										"0": "1",
										"1": "2.955385293728607",
										"2": "4624873.580000016"
									},
									{
										"0": "6",
										"1": "3.0823106614325817",
										"2": "187660.31999999986"
									},
									{
										"0": "3",
										"1": "3.124120509875714",
										"2": "274744.5299999999"
									},
									{
										"0": "5",
										"1": "3.1096431007047056",
										"2": "314624.36"
									},
									{
										"0": "9",
										"1": "6.23",
										"2": "49.84"
									},
									{
										"0": "4",
										"1": "3.1320803741555516",
										"2": "126570.5"
									},
									{
										"0": "8",
										"1": "7.831666666666667",
										"2": "46.99"
									},
									{
										"0": "7",
										"1": "2.382",
										"2": "11.91"
									},
									{
										"0": "2",
										"1": "3.1983281312300678",
										"2": "1026740.0900000012"
									},
									{
										"0": "0",
										"1": "2.93658769984829",
										"2": "50327.23999999999"
									}
								],
								"schema": [
									{
										"key": "0",
										"name": "passengerCount",
										"type": "int"
									},
									{
										"key": "1",
										"name": "AvgTripDistance",
										"type": "double"
									},
									{
										"key": "2",
										"name": "SumTripDistance",
										"type": "double"
									}
								],
								"truncated": false
							},
							"isSummary": false,
							"language": "scala"
						},
						"persist_state": {
							"view": {
								"type": "details",
								"chartOptions": {
									"chartType": "bar",
									"aggregationType": "sum",
									"categoryFieldKeys": [
										"1"
									],
									"seriesFieldKeys": [
										"0"
									],
									"isStacked": false
								}
							}
						}
					}
				}
			},
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "Synapse PySpark"
			},
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/7498e10a-1544-41e2-a9d0-35fd5695f525/resourceGroups/vksynapaerg/providers/Microsoft.Synapse/workspaces/vksynapse/bigDataPools/SampleSpark",
				"name": "SampleSpark",
				"type": "Spark",
				"endpoint": "https://vksynapse.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/SampleSpark",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net"
				},
				"sparkVersion": "3.1",
				"nodeCount": 3,
				"cores": 8,
				"memory": 56,
				"extraHeader": null
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "markdown",
				"source": [
					"# Explore NYC Yellow Taxi Data using Spark\n",
					"\n",
					"In this notebook, you'll learn the basic steps to load and analyze an Open Dataset that tracks NYC Yellow Taxi trips with Apache Spark for Azure Synapse.\n",
					"\n",
					"\n",
					""
				],
				"attachments": null
			},
			{
				"cell_type": "markdown",
				"source": [
					"## Load Data\n",
					"\n",
					"Read NYC Yellow Taxi data as a Spark DataFrame object to manipulate."
				],
				"attachments": null
			},
			{
				"cell_type": "code",
				"source": [
					"# Read NYC yellow cab data from Azure Open Datasets\n",
					"from azureml.opendatasets import NycTlcYellow\n",
					"\n",
					"from datetime import datetime\n",
					"from dateutil import parser\n",
					"\n",
					"end_date = parser.parse('2018-05-08 00:00:00')\n",
					"start_date = parser.parse('2018-05-01 00:00:00')\n",
					"\n",
					"nyc_tlc = NycTlcYellow(start_date=start_date, end_date=end_date)\n",
					"df_nyc_tlc = nyc_tlc.to_spark_dataframe()"
				],
				"attachments": null,
				"execution_count": 1
			},
			{
				"cell_type": "markdown",
				"source": [
					"## Analyze the NYC Taxi data using Spark and notebooks\n",
					""
				],
				"attachments": null
			},
			{
				"cell_type": "code",
				"source": [
					"df_nyc_tlc.printSchema()"
				],
				"attachments": null,
				"execution_count": 2
			},
			{
				"cell_type": "code",
				"metadata": {
					"diagram": {
						"activateDiagramType": 1,
						"chartConfig": {
							"category": "bar",
							"keys": [
								"AvgTripDistance"
							],
							"values": [
								"passengerCount"
							],
							"yLabel": "passengerCount",
							"xLabel": "AvgTripDistance",
							"aggregation": "SUM",
							"aggByBackend": false
						},
						"aggData": "{\"passengerCount\":{\"2.382\":7,\"2.9365876998482907\":0,\"2.955385293728598\":1,\"3.0823106614325835\":6,\"3.1096431007047065\":5,\"3.124120509875713\":3,\"3.132080374155551\":4,\"3.1983281312300624\":2,\"6.23\":9,\"7.831666666666666\":8}}",
						"isSummary": false,
						"previewData": {
							"filter": null
						},
						"isSql": false
					},
					"collapsed": false
				},
				"source": [
					"from pyspark.sql import functions as F\n",
					"df_nyc = df_nyc_tlc.groupBy(\"passengerCount\").agg(F.avg('tripDistance').alias('AvgTripDistance'), F.sum('tripDistance').alias('SumTripDistance'))\n",
					"display(df_nyc)"
				],
				"attachments": null,
				"execution_count": 3
			},
			{
				"cell_type": "markdown",
				"source": [
					"## Customize data visualization with Spark and notebooks\n",
					"You can control how charts render by using notebooks. The following code shows a simple example. It uses the popular libraries matplotlib and seaborn. The code renders the same kind of line chart as the SQL queries we ran earlier.\n",
					"\n",
					""
				],
				"attachments": null
			},
			{
				"cell_type": "code",
				"source": [
					"import matplotlib.pyplot\n",
					"import seaborn\n",
					"\n",
					"seaborn.set(style = \"whitegrid\")\n",
					"pdf_nyc = df_nyc.toPandas()\n",
					"seaborn.lineplot(x=\"passengerCount\", y=\"SumTripDistance\" , data = pdf_nyc)\n",
					"seaborn.lineplot(x=\"passengerCount\", y=\"AvgTripDistance\" , data = pdf_nyc)\n",
					"matplotlib.pyplot.show()"
				],
				"attachments": null,
				"execution_count": 4
			},
			{
				"cell_type": "markdown",
				"source": [
					"## Clean up resources\n",
					"To ensure the Spark instance is shut down, end any connected sessions(notebooks). The pool shuts down when the **idle time** specified in the Apache Spark pool is reached. You can also select **stop session** from the status bar at the upper right of the notebook.\n",
					"\n",
					"![stopsession](https://adsnotebookrelease.blob.core.windows.net/adsnotebookrelease/adsnotebook/image/stopsession.png)"
				],
				"attachments": null
			}
		]
	}
}